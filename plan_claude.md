ğŸ“‹ PLAN DE IMPLEMENTACIÃ“N: Memoria SemÃ¡ntica para WhatsApp Agent

  ğŸ¯ Objetivo

  Integrar memoria semÃ¡ntica funcional entre mensajes usando LangGraph BaseStore con bÃºsqueda semÃ¡ntica real.

  ---
  ğŸ“š Arquitectura Recomendada (Basada en Docs de LangGraph)

  SegÃºn la https://langchain-ai.github.io/langgraph/how-tos/memory/semantic-search/, tenemos dos opciones:

  OpciÃ³n A: InMemoryStore con Embeddings Reales âœ… RECOMENDADA

  - Ventajas: FÃ¡cil de implementar, bÃºsqueda semÃ¡ntica nativa, sin setup adicional
  - Desventajas: No persistente (se pierde al reiniciar)
  - Ideal para: Desarrollo y producciÃ³n con checkpointers para persistencia

  OpciÃ³n B: PostgresStore

  - Ventajas: Persistente, integraciÃ³n con pgvector existente
  - Desventajas: Requiere migraciÃ³n de datos, mÃ¡s complejo
  - Ideal para: ProducciÃ³n a largo plazo

  DecisiÃ³n: Empezaremos con OpciÃ³n A (InMemoryStore mejorado) porque:
  1. Ya tienes PostgreSQL para episodios (Nodo 3)
  2. PostgresSaver ya maneja persistencia de checkpoints
  3. MÃ¡s rÃ¡pido de implementar y probar

  ---
  ğŸ”§ FASE 1: Configurar InMemoryStore con Embeddings Reales

  Paso 1.1: Actualizar src/memory/store_config.py

  Cambios necesarios:
  # âŒ ELIMINAR: Embeddings falsos basados en hash
  def simple_embed(texts: list[str]) -> list[list[float]]:
      hash_val = int(hashlib.md5(text.encode()).hexdigest(), 16)
      # ...

  # âœ… AGREGAR: Embeddings reales con Sentence Transformers
  from langchain_community.embeddings import HuggingFaceEmbeddings

  def get_memory_store(reset: bool = False) -> InMemoryStore:
      global _store_instance

      if reset or _store_instance is None:
          # Usar el mismo modelo que en embeddings locales (consistency)
          embeddings = HuggingFaceEmbeddings(
              model_name="sentence-transformers/paraphrase-MiniLM-L6-v2",
              model_kwargs={'device': 'cpu'}
          )

          _store_instance = InMemoryStore(
              index={
                  "embed": embeddings,  # âœ… Embeddings reales
                  "dims": 384,          # DimensiÃ³n del modelo
                  "fields": ["content"] # Campo a embeddear
              }
          )
          logger.info("Memory store inicializado con embeddings reales")

      return _store_instance

  Referencias:
  - https://www.blog.langchain.com/semantic-search-for-langgraph-memory/
  - https://langchain-ai.github.io/langgraph/how-tos/memory/semantic-search/

  ---
  ğŸ”§ FASE 2: Integrar Memory Store en el Grafo de WhatsApp

  Paso 2.1: Modificar src/graph_whatsapp.py - Inicializar Store

  UbicaciÃ³n: FunciÃ³n crear_grafo() (lÃ­nea 298)

  def crear_grafo() -> StateGraph:
      logger.info("ğŸ—ï¸  Construyendo grafo de WhatsApp Agent...")

      # âœ… AGREGAR: Inicializar memory store
      from src.memory import get_memory_store
      memory_store = get_memory_store()
      logger.info("    âœ… Memory store inicializado")

      # Crear grafo
      builder = StateGraph(WhatsAppAgentState)

      # ... (agregar nodos)

      # Configurar PostgresSaver para checkpoints
      checkpointer = PostgresSaver(conn) if database_url else None

      # âœ… MODIFICAR: Compilar con AMBOS (store + checkpointer)
      if checkpointer:
          graph = builder.compile(
              checkpointer=checkpointer,
              store=memory_store  # âœ… Pasar store al compilar
          )
          logger.info("    âœ… Grafo compilado con store + checkpointer")
      else:
          graph = builder.compile(store=memory_store)
          logger.info("    âœ… Grafo compilado con store")

      return graph

  Referencia:
  - https://docs.langchain.com/oss/python/langgraph/graph-api

  ---
  ğŸ”§ FASE 3: Acceder al Store en los Nodos

  SegÃºn la https://github.com/langchain-ai/langgraph/discussions/341, hay 3 formas de acceder al store en nodos.

  OpciÃ³n Recomendada: Usar get_store() de LangGraph âœ…

  Ventajas:
  - No requiere cambiar firmas de funciones
  - Compatible con cÃ³digo existente
  - LangGraph inyecta automÃ¡ticamente el store

  Paso 3.1: Modificar src/nodes/ejecucion_herramientas_node.py

  Agregar imports:
  from langgraph.config import get_store
  from src.memory import get_user_preferences

  Modificar funciÃ³n nodo_ejecucion_herramientas() (lÃ­nea 399):

  def nodo_ejecucion_herramientas(state: WhatsAppAgentState) -> Dict:
      log_separator(logger, "NODO_5_EJECUCION_HERRAMIENTAS", "INICIO")

      # âœ… AGREGAR: Obtener store y preferencias
      try:
          store = get_store()
          user_id = state.get('user_id', 'default_user')
          preferencias = get_user_preferences(store, user_id)

          # Extraer preferencias relevantes
          timezone_pref = preferencias.get("user_preferences", {}).get("timezone", "America/Tijuana")
          preferred_times = preferencias.get("user_preferences", {}).get("preferred_meeting_times", [])
          language_pref = preferencias.get("user_preferences", {}).get("language_preference", "formal")

          logger.info(f"    ğŸ‘¤ Preferencias cargadas: timezone={timezone_pref}, estilo={language_pref}")

      except Exception as e:
          logger.warning(f"    âš ï¸  No se pudieron cargar preferencias: {e}")
          preferencias = {}
          timezone_pref = "America/Tijuana"
          preferred_times = []
          language_pref = "formal"

      # ... (resto del cÃ³digo)

  Modificar funciÃ³n construir_prompt_orquestador() (lÃ­nea 310):

  def construir_prompt_orquestador(
      tiempo_context: str,
      resultados_google: List[Dict],
      contexto_episodico: Dict,
      mensaje_usuario: str,
      preferencias_usuario: Dict  # âœ… NUEVO PARÃMETRO
  ) -> str:
      # Formatear preferencias
      prefs_str = ""
      if preferencias_usuario:
          user_prefs = preferencias_usuario.get("user_preferences", {})
          timezone = user_prefs.get("timezone", "America/Tijuana")
          language = user_prefs.get("language_preference", "formal")
          preferred_times = user_prefs.get("preferred_meeting_times", [])

          prefs_str = f"""
  PREFERENCIAS DEL USUARIO:
  - Zona horaria: {timezone}
  - Estilo de comunicaciÃ³n: {language}
  - Horarios preferidos: {', '.join(preferred_times) if preferred_times else 'No especificado'}
  """

      # ... (resto del prompt con prefs_str incluido)

  Actualizar llamada al Orquestador (lÃ­nea 557):

  prompt = construir_prompt_orquestador(
      tiempo_context=tiempo_contexto,
      resultados_google=resultados,
      contexto_episodico=contexto_episodico,
      mensaje_usuario=mensaje_usuario,
      preferencias_usuario=preferencias  # âœ… PASAR PREFERENCIAS
  )

  ---
  ğŸ”§ FASE 4: Actualizar Preferencias AutomÃ¡ticamente

  Paso 4.1: Modificar src/memory/semantic.py

  Implementar extracciÃ³n de preferencias con LLM:

  def update_semantic_memory(
      state: dict,
      store: BaseStore,
      user_id: str,
      llm: Optional[Any] = None
  ) -> Dict[str, Any]:
      namespace = ("semantic", user_id)
      current_memory = get_user_preferences(store, user_id)

      # âœ… IMPLEMENTAR: ExtracciÃ³n con LLM estructurado
      if llm and state.get("messages"):
          try:
              recent_messages = state["messages"][-5:]
              messages_text = "\n".join([
                  f"{msg.get('role', 'unknown')}: {msg.get('content', '')}"
                  for msg in recent_messages
              ])

              # Usar structured output de OpenAI/Anthropic
              from pydantic import BaseModel, Field

              class PreferencesUpdate(BaseModel):
                  timezone: Optional[str] = Field(None, description="Zona horaria mencionada")
                  preferred_times: Optional[List[str]] = Field(None, description="Horarios preferidos")
                  language_preference: Optional[str] = Field(None, description="formal o informal")

              prompt = f"""Analiza esta conversaciÃ³n y extrae SOLO nueva informaciÃ³n sobre preferencias:

  ConversaciÃ³n:
  {messages_text}

  Preferencias actuales:
  {json.dumps(current_memory, indent=2)}

  Si NO hay nueva informaciÃ³n relevante, devuelve campos null."""

              # Invocar con structured output
              response = llm.with_structured_output(PreferencesUpdate).invoke(prompt)

              # Actualizar solo si hay cambios
              if response.timezone or response.preferred_times or response.language_preference:
                  if response.timezone:
                      current_memory["user_preferences"]["timezone"] = response.timezone
                  if response.preferred_times:
                      current_memory["user_preferences"]["preferred_meeting_times"] = response.preferred_times
                  if response.language_preference:
                      current_memory["user_preferences"]["language_preference"] = response.language_preference

                  logger.info(f"âœ… Preferencias actualizadas para {user_id}")

          except Exception as e:
              logger.error(f"Error extrayendo preferencias: {e}")

      # Actualizar timestamp y guardar
      current_memory["last_updated"] = datetime.now().isoformat()
      store.put(namespace, "preferences", current_memory)

      return current_memory

  Paso 4.2: Llamar a update_semantic_memory en Nodo 6

  Modificar src/nodes/generacion_resumen_node.py:

  from langgraph.config import get_store
  from src.memory import update_semantic_memory

  def nodo_generacion_resumen(state: WhatsAppAgentState) -> Dict:
      # ... (generar resumen)

      # âœ… AGREGAR: Actualizar preferencias despuÃ©s del resumen
      try:
          store = get_store()
          user_id = state.get('user_id')

          # Usar LLM para actualizar preferencias
          update_semantic_memory(state, store, user_id, llm=llm_orquestador)
          logger.info("    âœ… Preferencias actualizadas con contexto de conversaciÃ³n")

      except Exception as e:
          logger.warning(f"    âš ï¸  Error actualizando preferencias: {e}")

      return {'resumen_actual': resumen}

  ---
  ğŸ”§ FASE 5: Unificar Memoria EpisÃ³dica con Memory Store

  OpciÃ³n A: Mantener PostgreSQL para Episodios âœ… RECOMENDADA

  - Nodo 3 sigue usando memoria_episodica (PostgreSQL + pgvector)
  - InMemoryStore solo para preferencias semÃ¡nticas
  - Ventaja: No requiere migraciÃ³n de datos

  OpciÃ³n B: Migrar Episodios a InMemoryStore

  - Consolidar todo en un solo sistema
  - Desventaja: Perder persistencia de episodios

  DecisiÃ³n: Mantener arquitectura hÃ­brida:
  - InMemoryStore: Preferencias del usuario (memoria semÃ¡ntica)
  - PostgreSQL: ResÃºmenes de conversaciones (memoria episÃ³dica)
  - PostgresSaver: Checkpoints para rolling window

  ---
  ğŸ“Š RESUMEN DE CAMBIOS
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                 Archivo                  â”‚                     Cambios                      â”‚   Prioridad   â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ src/memory/store_config.py               â”‚ Reemplazar embeddings hash por reales            â”‚ ğŸ”´ CRÃTICO    â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ src/graph_whatsapp.py                    â”‚ Inicializar y pasar store al compilar            â”‚ ğŸ”´ CRÃTICO    â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ src/nodes/ejecucion_herramientas_node.py â”‚ Cargar preferencias con get_store()              â”‚ ğŸ”´ CRÃTICO    â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ src/memory/semantic.py                   â”‚ Implementar extracciÃ³n LLM con structured output â”‚ ğŸŸ¡ IMPORTANTE â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ src/nodes/generacion_resumen_node.py     â”‚ Llamar a update_semantic_memory()                â”‚ ğŸŸ¡ IMPORTANTE â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ---
  âœ… ORDEN DE IMPLEMENTACIÃ“N

  1. Fase 1 â†’ Arreglar embeddings (15 min)
  2. Fase 2 â†’ Integrar store en grafo (10 min)
  3. Fase 3 â†’ Cargar preferencias en Nodo 5 (20 min)
  4. Fase 4 â†’ Actualizar preferencias automÃ¡ticamente (30 min)
  5. Fase 5 â†’ Testing y validaciÃ³n (30 min)

  Tiempo total estimado: ~2 horas

  ---
  ğŸ”— Referencias de DocumentaciÃ³n

  - https://langchain-ai.github.io/langgraph/how-tos/memory/semantic-search/
  - https://www.blog.langchain.com/semantic-search-for-langgraph-memory/
  - https://docs.langchain.com/oss/python/langgraph/memory
  - https://docs.langchain.com/oss/python/langgraph/graph-api
  - https://reference.langchain.com/python/langgraph/store/

  ---