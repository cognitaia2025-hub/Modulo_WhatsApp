"""
Nodo 4: Selecci√≥n Inteligente de Herramientas (Memoria Procedimental)

Este nodo determina qu√© herramientas de Google Calendar necesita el agente
bas√°ndose en la conversaci√≥n y el contexto epis√≥dico.

Estrategia:
1. Consulta PostgreSQL (herramientas_disponibles) con cach√© de 5 minutos
2. Usa LLM (DeepSeek) para analizar intenci√≥n del usuario
3. Selecciona herramientas relevantes comparando con descripciones
4. Actualiza state['herramientas_seleccionadas']
"""

import logging
from typing import Dict, List
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from dotenv import load_dotenv
import os

from src.state.agent_state import WhatsAppAgentState
from src.database import get_herramientas_disponibles
from src.utils.logging_config import (
    log_separator, 
    log_node_io, 
    log_llm_interaction,
    log_user_message
)

load_dotenv()
logger = logging.getLogger(__name__)

# LLM principal para selecci√≥n (DeepSeek)
llm_primary = ChatOpenAI(
    model="deepseek-chat",
    temperature=0,
    max_tokens=100,
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com/v1",
    timeout=20.0,
    max_retries=0  # ‚úÖ Reintentos los maneja LangGraph
)

# Fallback: Claude Haiku 4.5
llm_fallback = ChatAnthropic(
    model="claude-3-5-haiku-20241022",
    temperature=0,
    max_tokens=100,
    api_key=os.getenv("ANTHROPIC_API_KEY"),
    timeout=15.0,
    max_retries=0
)

# Selector con fallback autom√°tico
llm_selector = llm_primary.with_fallbacks([llm_fallback])


def extraer_ultimo_mensaje_usuario(state: WhatsAppAgentState) -> str:
    """
    Extrae el √∫ltimo mensaje del usuario desde el historial
    
    Returns:
        String con el mensaje o cadena vac√≠a
    """
    mensajes = state.get('messages', [])
    
    # Buscar √∫ltimo mensaje de rol 'user'
    for mensaje in reversed(mensajes):
        if isinstance(mensaje, dict):
            if mensaje.get('role') == 'user':
                return mensaje.get('content', '')
        elif hasattr(mensaje, 'type'):
            if mensaje.type == 'human':
                return mensaje.content
    
    return ""


def construir_prompt_seleccion(
    mensaje_usuario: str,
    herramientas: List[Dict[str, str]],
    contexto_episodico: Dict = None
) -> str:
    """
    Construye el prompt para el LLM de selecci√≥n de herramientas
    
    Args:
        mensaje_usuario: √öltimo mensaje del usuario
        herramientas: Lista de dicts con id_tool y description
        contexto_episodico: Contexto hist√≥rico (opcional)
        
    Returns:
        Prompt estructurado para el LLM
    """
    # Formatear herramientas disponibles SIN NUMERACI√ìN (usar vi√±etas)
    herramientas_str = "\n".join([
        f"‚Ä¢ {h['id_tool']} ‚Äî {h['description']}"
        for h in herramientas
    ])
    
    # Agregar contexto epis√≥dico si existe
    contexto_str = ""
    if contexto_episodico and contexto_episodico.get('episodios_recuperados'):
        contexto_str = f"\n\nContexto hist√≥rico relevante:\n{contexto_episodico.get('texto_formateado', '')}\n"
    
    prompt = f"""Eres un selector de herramientas de calendario. Tu trabajo es √öNICAMENTE responder con el ID exacto de la herramienta.

HERRAMIENTAS DISPONIBLES:
{herramientas_str}

MENSAJE DEL USUARIO:
"{mensaje_usuario}"{contexto_str}

REGLAS ESTRICTAS:
1. NO utilices n√∫meros, √≠ndices ni explicaciones
2. Responde √öNICAMENTE con el ID exacto de la herramienta (ej: list_calendar_events)
3. Si necesitas m√∫ltiples herramientas, sep√°ralas con comas sin espacios
4. Si NO est√°s seguro o NO se necesita ninguna herramienta, responde: NONE
5. Tu respuesta debe contener SOLO el ID de la herramienta, nada m√°s

GU√çA R√ÅPIDA:
- ¬øPregunta por agenda/eventos? ‚Üí list_calendar_events
- ¬øCrear/agendar evento? ‚Üí create_calendar_event
- ¬øModificar hora/detalles? ‚Üí update_calendar_event
- ¬øEliminar evento? ‚Üí delete_calendar_event
- ¬øBuscar eventos? ‚Üí search_calendar_events
- ¬øSin acci√≥n de calendario? ‚Üí NONE

RESPUESTA (solo ID o NONE):"""
    
    return prompt


def parsear_respuesta_llm(respuesta: str, herramientas_disponibles: List[Dict[str, str]]) -> List[str]:
    """
    Parsea la respuesta del LLM a lista de IDs con robustez contra errores comunes
    
    Args:
        respuesta: String del LLM (ej: "list_calendar_events" o "1")
        herramientas_disponibles: Lista de herramientas con id_tool para mapeo
        
    Returns:
        Lista de IDs limpia (ej: ['list_calendar_events'])
    """
    # Limpieza profunda: quitar espacios, saltos de l√≠nea, comillas
    respuesta = respuesta.strip().replace('\n', '').replace('"', '').replace("'", '')
    
    logger.info(f"    [DEBUG] Respuesta limpia: '{respuesta}'")
    
    # Caso: No necesita herramientas
    if respuesta.upper() == "NONE" or respuesta == "":
        logger.info("    [DEBUG] Sin herramientas (NONE)")
        return []
    
    # MAPEO DE SEGURIDAD: Si el LLM responde con n√∫mero, mapearlo al ID
    if respuesta.isdigit():
        indice = int(respuesta) - 1  # "1" ‚Üí √≠ndice 0
        if 0 <= indice < len(herramientas_disponibles):
            id_mapeado = herramientas_disponibles[indice]['id_tool']
            logger.warning(f"    ‚ö†Ô∏è  LLM respondi√≥ con n√∫mero '{respuesta}', mapeando a '{id_mapeado}'")
            return [id_mapeado]
        else:
            logger.error(f"    ‚ùå √çndice '{respuesta}' fuera de rango (max: {len(herramientas_disponibles)})")
            return []
    
    # Limpiar y separar por comas
    ids = [
        id_tool.strip().lower()
        for id_tool in respuesta.split(',')
        if id_tool.strip()
    ]
    
    # Validar contra IDs reales en la base de datos
    ids_validos_db = [h['id_tool'] for h in herramientas_disponibles]
    logger.info(f"    [DEBUG] IDs V√°lidos en DB: {ids_validos_db}")
    
    ids_finales = []
    for id_tool in ids:
        if id_tool in ids_validos_db:
            ids_finales.append(id_tool)
        else:
            logger.warning(f"    ‚ö†Ô∏è  ID '{id_tool}' no existe en DB, ignorando")
    
    return ids_finales


def nodo_seleccion_herramientas(state: WhatsAppAgentState) -> Dict:
    """
    Nodo 4: Selecciona herramientas de Google Calendar bas√°ndose en la conversaci√≥n
    
    Flujo:
    1. Obtiene herramientas disponibles (con cach√© de 5 min)
    2. Extrae √∫ltimo mensaje del usuario
    3. Consulta LLM para selecci√≥n inteligente
    4. Parsea respuesta a lista de IDs
    5. Actualiza state['herramientas_seleccionadas']
    
    Args:
        state: WhatsAppAgentState con mensajes y contexto
        
    Returns:
        Dict con 'herramientas_seleccionadas': List[str]
    """
    log_separator(logger, "NODO_4_SELECCION_HERRAMIENTAS", "INICIO")
    
    # Log del input del nodo
    state_input = f"messages: {len(state.get('messages', []))} mensajes\ncontexto_episodico: {bool(state.get('contexto_episodico'))}"
    log_node_io(logger, "INPUT", "NODO_4_SELECCION", state_input)
    
    try:
        # 1. Obtener herramientas disponibles (usa cach√© si est√° vigente)
        herramientas = get_herramientas_disponibles()
        logger.info(f"    üì¶ Herramientas disponibles: {len(herramientas)}")
        
        # 2. Extraer √∫ltimo mensaje del usuario
        mensaje_usuario = extraer_ultimo_mensaje_usuario(state)
        
        if not mensaje_usuario:
            logger.warning("    ‚ö†Ô∏è  No se encontr√≥ mensaje del usuario")
            return {'herramientas_seleccionadas': []}
        
        log_user_message(logger, mensaje_usuario)
        
        # 3. Obtener contexto epis√≥dico si existe
        contexto = state.get('contexto_episodico')
        tiene_contexto = contexto and contexto.get('episodios_recuperados')
        
        logger.info(f"    üìñ Contexto epis√≥dico disponible: {tiene_contexto}")
        
        # 4. Construir prompt para LLM
        prompt = construir_prompt_seleccion(
            mensaje_usuario=mensaje_usuario,
            herramientas=herramientas,
            contexto_episodico=contexto
        )
        
        # 5. Consultar LLM para selecci√≥n inteligente
        logger.info("    ü§ñ Consultando LLM para selecci√≥n...")
        
        respuesta = llm_selector.invoke(prompt)
        respuesta_texto = respuesta.content.strip()
        
        # Log detallado de interacci√≥n con LLM
        log_llm_interaction(logger, "DeepSeek/Claude", prompt, respuesta_texto, truncate_prompt=800, truncate_response=200)
        
        # 6. Parsear respuesta a lista de IDs con mapeo robusto
        ids_seleccionados = parsear_respuesta_llm(respuesta_texto, herramientas)
        
        logger.info(f"    ‚úÖ Herramientas seleccionadas: {ids_seleccionados}")
        
        # Log del output del nodo
        output_data = f"herramientas_seleccionadas: {ids_seleccionados}"
        log_node_io(logger, "OUTPUT", "NODO_4_SELECCION", output_data)
        log_separator(logger, "NODO_4_SELECCION_HERRAMIENTAS", "FIN")
        
        return {
            'herramientas_seleccionadas': ids_seleccionados
        }
        
    except Exception as e:
        # Fallback: selecci√≥n por defecto (list + create)
        logger.error(f"    ‚ùå Error en selecci√≥n de herramientas: {e}")
        logger.info("    üîÑ Usando herramientas por defecto (fallback)")
        
        log_separator(logger, "NODO_4_SELECCION_HERRAMIENTAS", "FIN")
        
        return {
            'herramientas_seleccionadas': ['list_calendar_events', 'create_calendar_event']
        }


# Wrapper para compatibilidad con grafo
def nodo_seleccion_herramientas_wrapper(state: WhatsAppAgentState) -> WhatsAppAgentState:
    """
    Wrapper que mantiene la firma esperada por el grafo
    """
    resultado = nodo_seleccion_herramientas(state)
    
    # Actualizar estado
    state['herramientas_seleccionadas'] = resultado['herramientas_seleccionadas']
    
    return state
