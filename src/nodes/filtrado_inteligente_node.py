"""
Nodo 2: Filtrado Inteligente con Detecci√≥n de Intenci√≥n

FUNCIONES PRINCIPALES:
1. Detectar la intenci√≥n del usuario usando contexto completo (N1)
2. Determinar si la intenci√≥n es CLARA o NECESITA M√ÅS INFORMACI√ìN
3. Si intenci√≥n no es clara ‚Üí Pedir aclaraciones (loop interno, no avanza)
4. Si intenci√≥n es clara ‚Üí Clasificar y pasar al siguiente nodo

CLASIFICACIONES POSIBLES:
- 'personal': Eventos de calendario personal
- 'medica': Solicitudes m√©dicas (solo doctores)
- 'solicitud_cita_paciente': Pacientes externos solicitan citas
- 'chat': Conversaci√≥n casual (pero intenci√≥n clara)
- 'necesita_aclaracion': Intenci√≥n NO clara, requiere m√°s informaci√≥n

ESTRATEGIA DE CONVERSACIONES FRAGMENTADAS:
‚Ä¢ Usuario: "Hola" ‚Üí necesita_aclaracion ‚Üí Responde: "¬øEn qu√© puedo ayudarte?"
‚Ä¢ Usuario: "quiero agendar" ‚Üí solicitud_cita_paciente ‚Üí Pasa a recepcionista
‚Ä¢ Usuario: "mi nombre es Juan" (sin contexto) ‚Üí necesita_aclaracion ‚Üí "¬øQu√© necesitas hacer, Juan?"

ARQUITECTURA:
1. N0 (Identificaci√≥n) ‚Üí Carga user_id, tipo_usuario en el state
2. N1 (Cach√©) ‚Üí Usa user_id para recuperar contexto hist√≥rico
3. N2 (Este nodo) ‚Üí Usa contexto + tipo_usuario para clasificar
4. Si clara ‚Üí Siguiente nodo | Si no clara ‚Üí Loop (pide aclaraciones)
"""

import logging
import time
from typing import Literal, Any, Optional, List, cast
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage, AIMessage
from langgraph.types import Command
from pydantic import BaseModel, Field, SecretStr
from dotenv import load_dotenv
import os
import psycopg
from psycopg.types.json import Json

from src.state.agent_state import WhatsAppAgentState

load_dotenv()
logger = logging.getLogger(__name__)

# Configuraci√≥n de LLMs
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://postgres:postgres@localhost:5434/agente_whatsapp")


# ==================== PYDANTIC MODEL ====================

class ClasificacionResponse(BaseModel):
    """Respuesta estructurada del clasificador."""
    
    clasificacion: Literal["personal", "medica", "solicitud_cita_paciente", "chat", "necesita_aclaracion"] = Field(
        description="""
        Categor√≠a del mensaje:
        - personal: Eventos de calendario personal (intenci√≥n CLARA)
        - medica: Solicitudes m√©dicas de doctores (intenci√≥n CLARA)
        - solicitud_cita_paciente: Paciente externo pide cita (intenci√≥n CLARA)
        - chat: Conversaci√≥n casual pero intenci√≥n clara (despedidas, agradecimientos)
        - necesita_aclaracion: Intenci√≥n NO clara, requiere m√°s informaci√≥n del usuario
        """
    )
    
    confianza: float = Field(
        ge=0.0,
        le=1.0,
        description="Nivel de confianza en la clasificaci√≥n (0.0 a 1.0)"
    )
    
    razonamiento: str = Field(
        description="Breve explicaci√≥n de por qu√© se eligi√≥ esta clasificaci√≥n"
    )
    
    pregunta_aclaracion: Optional[str] = Field(
        default=None,
        description="Si clasificacion='necesita_aclaracion', pregunta para pedir m√°s informaci√≥n"
    )


# ==================== CONFIGURACI√ìN LLM CON STRUCTURED OUTPUT ====================

# LLM primario: DeepSeek con JSON mode (m√°s compatible)
llm_primary_base = ChatOpenAI(
    model="deepseek-chat",
    temperature=0,
    max_tokens=200,
    api_key=SecretStr(os.getenv("DEEPSEEK_API_KEY") or ""),
    base_url="https://api.deepseek.com/v1",
    timeout=10.0,
    max_retries=0,
    model_kwargs={"response_format": {"type": "json_object"}}
)

# LLM fallback: Claude Sonnet (soporta structured output)
llm_fallback_base = ChatAnthropic(
    model_name="claude-3-5-sonnet-20240620",
    temperature=0,
    max_tokens=200,
    api_key=SecretStr(os.getenv("ANTHROPIC_API_KEY") or ""),
    timeout=10.0,
    max_retries=0,
    stop=None
)

# Configurar structured output - usar method="json_mode" para mayor compatibilidad
llm_primary = llm_primary_base.with_structured_output(  # type: ignore[no-untyped-call]
    ClasificacionResponse,
    method="json_mode"
)

llm_fallback = llm_fallback_base.with_structured_output(  # type: ignore[no-untyped-call]
    ClasificacionResponse
)


# ==================== CONSTANTES ====================

# ‚úÖ ESTADOS CORREGIDOS (Sincronizados con logs del recepcionista)
ESTADOS_FLUJO_ACTIVO = [
    'solicitando_nombre',
    'recolectando_slots',
    'confirmando_cita',
    'mostrando_opciones',
    # Estados legacy por compatibilidad
    'recolectando_fecha',
    'recolectando_hora', 
    'esperando_confirmacion'
]

# ‚úÖ MAPEO CORREGIDO - Todos los estados de cita van a recepcionista
MAPEO_ESTADO_A_NODO = {
    'solicitando_nombre': 'recepcionista',
    'recolectando_slots': 'recepcionista',
    'confirmando_cita': 'recepcionista',
    'mostrando_opciones': 'recepcionista',
    # Estados legacy
    'recolectando_fecha': 'recepcionista',
    'recolectando_hora': 'recepcionista',
    'esperando_confirmacion': 'recepcionista'
}


def construir_prompt_clasificacion(
    mensaje_usuario: str, 
    tipo_usuario: str,
    contexto_previo: List[str]
) -> List[Any]:
    """
    Construye prompt mejorado para clasificaci√≥n con detecci√≥n de intenci√≥n clara
    
    Args:
        mensaje_usuario: √öltimo mensaje del usuario
        tipo_usuario: Tipo de usuario (doctor, paciente_externo, admin)
        contexto_previo: Lista de mensajes previos de la conversaci√≥n
    """
    # Formatear contexto
    contexto_str = ""
    if contexto_previo:
        contexto_str = "\n".join([f"- {msg}" for msg in contexto_previo[-5:]])  # √öltimos 5 mensajes
    
    system_prompt = """Eres un clasificador de intenci√≥n para una cl√≠nica m√©dica.

Tu trabajo es DETERMINAR si la intenci√≥n del usuario es CLARA o NECESITA M√ÅS INFORMACI√ìN.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
CATEGOR√çAS CUANDO LA INTENCI√ìN ES CLARA
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. "personal" - Eventos de calendario personal
   ‚Ä¢ Usuario pide recordatorio personal
   ‚Ä¢ Menciona eventos no m√©dicos
   ‚Ä¢ Ejemplos CLAROS: "Recu√©rdame el cumplea√±os de Mar√≠a el viernes"

2. "medica" - Solicitudes m√©dicas (SOLO DOCTORES)
   ‚Ä¢ Doctor pregunta por paciente espec√≠fico
   ‚Ä¢ Doctor revisa historiales
   ‚Ä¢ Ejemplos CLAROS: "¬øC√≥mo est√° mi paciente Juan?", "Ver expediente de Mar√≠a"

3. "solicitud_cita_paciente" - Paciente externo pide cita
   ‚Ä¢ Menciona expl√≠citamente "cita", "agendar", "consulta"
   ‚Ä¢ Pregunta por disponibilidad
   ‚Ä¢ Ejemplos CLAROS: "Quiero una cita", "Necesito agendar", "¬øTienen espacio ma√±ana?"

4. "chat" - Conversaci√≥n casual CON INTENCI√ìN CLARA
   ‚Ä¢ Despedidas: "Adi√≥s", "Hasta luego", "Nos vemos"
   ‚Ä¢ Agradecimientos: "Gracias", "Muchas gracias", "Te agradezco"
   ‚Ä¢ Afirmaciones: "OK", "Entendido", "Perfecto"
   ‚Ä¢ ‚ö†Ô∏è NO uses "chat" para saludos iniciales sin intenci√≥n

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
CATEGOR√çA CUANDO LA INTENCI√ìN NO ES CLARA
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

5. "necesita_aclaracion" - Intenci√≥n NO clara
   ‚Ä¢ Saludos iniciales sin contexto: "Hola", "Buenos d√≠as"
   ‚Ä¢ Fragmentos de informaci√≥n: "mi nombre es Juan" (sin decir qu√© quiere)
   ‚Ä¢ Mensajes ambiguos: "Necesito ayuda" (sin especificar con qu√©)
   ‚Ä¢ Informaci√≥n personal sin solicitud: "Tengo 30 a√±os" (¬øy qu√© necesita?)
   
   ‚ö° ACCI√ìN REQUERIDA: Generar pregunta_aclaracion para pedir m√°s informaci√≥n
   
   Ejemplos de preguntas:
   ‚Ä¢ "¬°Hola! ¬øEn qu√© puedo ayudarte hoy?"
   ‚Ä¢ "Entendido, {nombre}. ¬øQu√© necesitas hacer?"
   ‚Ä¢ "Claro, ¬ønecesitas agendar una cita, revisar algo o consultar informaci√≥n?"

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
REGLAS DE CLASIFICACI√ìN
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ö†Ô∏è CR√çTICO:

1. USA EL CONTEXTO: Si los mensajes anteriores dan pistas, √∫salas
   ‚Ä¢ Contexto: ["Hola", "quiero agendar"] ‚Üí "solicitud_cita_paciente"
   ‚Ä¢ Sin contexto: "Hola" ‚Üí "necesita_aclaracion"

2. PACIENTES EXTERNOS:
   ‚Ä¢ Si intenci√≥n CLARA y NO es cita ‚Üí "necesita_aclaracion" + pregunta
   ‚Ä¢ Solo pueden: "solicitud_cita_paciente", "chat", "necesita_aclaracion"

3. CONFIANZA:
   ‚Ä¢ Alta (>0.9): Intenci√≥n muy clara
   ‚Ä¢ Media (0.5-0.9): Intenci√≥n probable pero con algo de ambig√ºedad
   ‚Ä¢ Baja (<0.5): Intenci√≥n poco clara ‚Üí "necesita_aclaracion"

4. PREGUNTA DE ACLARACI√ìN:
   ‚Ä¢ SIEMPRE incluir si clasificacion="necesita_aclaracion"
   ‚Ä¢ Debe ser espec√≠fica y natural
   ‚Ä¢ Puede mencionar info que el usuario ya dio

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
EJEMPLOS COMPLETOS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Entrada: "Hola"
Contexto: []
Usuario: paciente_externo
Salida: {
  "clasificacion": "necesita_aclaracion", 
  "confianza": 0.4,
  "razonamiento": "Saludo inicial sin contexto ni intenci√≥n",
  "pregunta_aclaracion": "¬°Hola! ¬øEn qu√© puedo ayudarte hoy?"
}

Entrada: "quiero agendar"
Contexto: ["Hola", "Buenos d√≠as"]
Usuario: paciente_externo
Salida: {
  "clasificacion": "solicitud_cita_paciente",
  "confianza": 0.95,
  "razonamiento": "Intenci√≥n clara de agendar cita",
  "pregunta_aclaracion": null
}

Entrada: "mi nombre es Juan"
Contexto: []
Usuario: paciente_externo
Salida: {
  "clasificacion": "necesita_aclaracion",
  "confianza": 0.3,
  "razonamiento": "Proporciona nombre pero no dice qu√© necesita",
  "pregunta_aclaracion": "Mucho gusto, Juan. ¬øQu√© necesitas hacer hoy?"
}

Entrada: "necesito ayuda"
Contexto: []
Usuario: paciente_externo
Salida: {
  "clasificacion": "necesita_aclaracion",
  "confianza": 0.4,
  "razonamiento": "Solicitud de ayuda pero no especifica con qu√©",
  "pregunta_aclaracion": "Claro, ¬ønecesitas agendar una cita o consultar algo?"
}

Entrada: "Gracias por todo"
Contexto: ["Quiero cita", "Te confirmo para ma√±ana 10am", "Perfecto"]
Usuario: paciente_externo
Salida: {
  "clasificacion": "chat",
  "confianza": 0.98,
  "razonamiento": "Agradecimiento al finalizar conversaci√≥n",
  "pregunta_aclaracion": null
}

Entrada: "¬øC√≥mo est√° Juan P√©rez?"
Contexto: []
Usuario: doctor
Salida: {
  "clasificacion": "medica",
  "confianza": 0.99,
  "razonamiento": "Doctor pregunta por paciente espec√≠fico",
  "pregunta_aclaracion": null
}"""

    # Formatear contexto previo
    contexto_display = f"\nContexto de conversaci√≥n previa:\n{contexto_str}" if contexto_str else "\nContexto: (Primera interacci√≥n)"

    user_prompt = f"""Clasifica este mensaje considerando el contexto completo:{contexto_display}

Mensaje actual: "{mensaje_usuario}"
Tipo de usuario: {tipo_usuario}

IMPORTANTE: 
- Si la intenci√≥n NO es clara ‚Üí clasificacion="necesita_aclaracion" + generar pregunta_aclaracion
- Si la intenci√≥n es clara ‚Üí clasificar en la categor√≠a correcta

Analiza y responde en formato JSON."""

    return [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]


def validar_clasificacion_por_tipo_usuario(
    clasificacion: str,
    tipo_usuario: str
) -> str:
    """
    Valida que la clasificaci√≥n sea compatible con el tipo de usuario
    
    Regla cr√≠tica: Pacientes externos SOLO pueden tener 'solicitud_cita_paciente'
    
    Args:
        clasificacion: Clasificaci√≥n del LLM
        tipo_usuario: Tipo de usuario
        
    Returns:
        Clasificaci√≥n validada (puede ser modificada)
    """
    # Pacientes externos: SOLO solicitud_cita_paciente o chat
    if tipo_usuario == "paciente_externo":
        if clasificacion in ["medica", "personal"]:
            logger.warning(
                f"‚ö†Ô∏è  Paciente externo clasificado como '{clasificacion}', "
                f"corrigiendo a 'solicitud_cita_paciente'"
            )
            return "solicitud_cita_paciente"
    
    # Doctores: todas las clasificaciones permitidas
    return clasificacion


def registrar_clasificacion_bd(
    user_id: str,
    session_id: str,
    mensaje: str,
    clasificacion: str,
    modelo_usado: str,
    tiempo_ms: int,
    herramientas_seleccionadas: Optional[List[Any]] = None
) -> None:
    """
    Registra clasificaci√≥n en la base de datos para auditor√≠a
    
    Args:
        user_id: ID del usuario (tel√©fono)
        session_id: ID de la sesi√≥n
        mensaje: Mensaje clasificado
        clasificacion: Clasificaci√≥n asignada
        modelo_usado: Modelo LLM usado
        tiempo_ms: Tiempo de procesamiento en ms
        herramientas_seleccionadas: Lista de herramientas seleccionadas
    """
    try:
        with psycopg.connect(DATABASE_URL) as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO clasificaciones_llm (
                        session_id,
                        user_id,
                        modelo,
                        clasificacion,
                        herramientas_seleccionadas,
                        mensaje_usuario,
                        tiempo_respuesta_ms
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s)
                """, (
                    session_id,
                    user_id,
                    modelo_usado,
                    clasificacion,
                    Json(herramientas_seleccionadas or []),
                    mensaje[:1000],  # Limitar tama√±o
                    tiempo_ms
                ))
                conn.commit()
        
        logger.info(f"‚úÖ Clasificaci√≥n registrada en BD: {clasificacion}")
    
    except Exception as e:
        logger.error(f"‚ùå Error registrando clasificaci√≥n: {e}")
        # No fallar el flujo principal si falla el registro


def nodo_filtrado_inteligente(state: WhatsAppAgentState) -> Command[Any]:
    """
    Nodo de filtrado inteligente con detecci√≥n de intenci√≥n clara
    
    L√ìGICA:
    1. Extrae contexto previo de N1 (cache)
    2. Analiza mensaje actual + contexto
    3. Si intenci√≥n NO clara ‚Üí Pide aclaraciones (loop interno)
    4. Si intenci√≥n clara ‚Üí Clasifica y pasa al siguiente nodo
    """
    logger.info("\n" + "=" * 70)
    logger.info("üîç NODO N2: FILTRADO INTELIGENTE + DETECCI√ìN DE INTENCI√ìN")
    logger.info("=" * 70)
    
    inicio = time.time()
    
    # Extraer datos del state
    messages = cast(List[Any], state.get("messages", []))
    tipo_usuario = str(state.get("tipo_usuario", "paciente_externo"))
    user_id = str(state.get("user_id", "unknown"))
    estado_conversacion = str(state.get("estado_conversacion", "inicial"))
    contexto_recuperado = cast(List[str], state.get("contexto_recuperado", []))
    
    logger.info(f"üë§ Usuario: {user_id} ({tipo_usuario})")
    logger.info(f"üìö Contexto recuperado (N1): {len(contexto_recuperado)} memorias")
    
    # ‚úÖ VALIDACI√ìN: Si hay flujo activo, saltar sin clasificar
    if estado_conversacion in ESTADOS_FLUJO_ACTIVO:
        goto_node = str(MAPEO_ESTADO_A_NODO.get(estado_conversacion, "generacion_resumen"))
        logger.info(f"   ‚ö° Flujo activo: {estado_conversacion} -> Saltando a {goto_node}")
        
        return Command(
            update={
                "requiere_clasificacion_llm": False,
                "ruta_siguiente": goto_node
            },
            goto=goto_node
        )
    
    # Extraer √∫ltimo mensaje y contexto previo de la conversaci√≥n actual
    ultimo_mensaje = ""
    contexto_conversacion: List[str] = []
    
    for msg_item in messages:
        # Manejo robusto de BaseMessage o dict
        if isinstance(msg_item, BaseMessage):
            content = msg_item.content
            # content puede ser str o list[str | dict]
            if isinstance(content, str):
                texto = content
            elif isinstance(content, list) and len(content) > 0:
                texto = str(content[0]) if content[0] else ""
            else:
                continue
            
            # Agregar al contexto (√∫ltimos 5 mensajes)
            if msg_item.type == "human":
                contexto_conversacion.append(f"Usuario: {texto}")
            elif msg_item.type == "ai":
                contexto_conversacion.append(f"Asistente: {texto}")
                
        elif isinstance(msg_item, dict):
            role = cast(Any, msg_item.get("role"))
            content_val = cast(Any, msg_item.get("content", ""))
            texto = str(content_val)
            
            if role == "user":
                contexto_conversacion.append(f"Usuario: {texto}")
            elif role == "assistant":
                contexto_conversacion.append(f"Asistente: {texto}")
    
    # El √∫ltimo mensaje del usuario
    for msg_item in reversed(messages):
        if isinstance(msg_item, BaseMessage):
            if msg_item.type == "human":
                content = msg_item.content
                if isinstance(content, str):
                    ultimo_mensaje = content
                elif isinstance(content, list) and len(content) > 0:
                    ultimo_mensaje = str(content[0]) if content[0] else ""
                break
        elif isinstance(msg_item, dict):
            role = cast(Any, msg_item.get("role"))
            if role == "user":
                content_val = cast(Any, msg_item.get("content", ""))
                ultimo_mensaje = str(content_val)
                break
    
    if not ultimo_mensaje:
        logger.warning("‚ö†Ô∏è  No se encontr√≥ mensaje del usuario")
        return Command(
            update={
                "clasificacion_mensaje": "chat",
                "confianza_clasificacion": 0.5
            },
            goto="generacion_resumen"
        )
    
    logger.info(f"üìù Mensaje: {ultimo_mensaje[:100]}...")
    logger.info(f"üí¨ Contexto conversaci√≥n: {len(contexto_conversacion)} mensajes")
    
    # Construir prompt con contexto
    # Tomar √∫ltimos 10 mensajes de contexto (5 intercambios)
    contexto_para_prompt = contexto_conversacion[-10:] if len(contexto_conversacion) > 10 else contexto_conversacion
    
    prompt_messages = construir_prompt_clasificacion(
        ultimo_mensaje, 
        tipo_usuario,
        contexto_para_prompt
    )
    
    # Llamar a LLM con fallback
    modelo_usado = "deepseek"
    
    try:
        logger.info("ü§ñ Llamando a DeepSeek con structured output...")
        resultado = cast(ClasificacionResponse, llm_primary.invoke(prompt_messages))
        modelo_usado = "deepseek"
    
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  DeepSeek fall√≥: {e}")
        logger.info("üîÑ Intentando con Claude (fallback)...")
        
        try:
            resultado = cast(ClasificacionResponse, llm_fallback.invoke(prompt_messages))
            modelo_usado = "claude"
        
        except Exception as e2:
            logger.error(f"‚ùå Ambos LLMs fallaron: {e2}")
            
            # Fallback final: pedir aclaraci√≥n
            return Command(
                update={
                    "clasificacion_mensaje": "necesita_aclaracion",
                    "confianza_clasificacion": 0.3,
                    "modelo_clasificacion_usado": "fallback",
                    "messages": messages + [AIMessage(content="Disculpa, tuve un problema t√©cnico. ¬øPodr√≠as decirme en qu√© puedo ayudarte?")]
                },
                goto="END"  # Loop: espera nuevo mensaje del usuario
            )
    
    # Extraer resultado
    clasificacion = resultado.clasificacion
    confianza = resultado.confianza
    razonamiento = resultado.razonamiento
    pregunta_aclaracion = resultado.pregunta_aclaracion
    
    logger.info(f"üìä Clasificaci√≥n: {clasificacion}")
    logger.info(f"üíØ Confianza: {confianza}")
    logger.info(f"üí≠ Razonamiento: {razonamiento}")
    
    # ‚úÖ CASO ESPECIAL: Intenci√≥n NO clara ‚Üí Pedir aclaraci√≥n (LOOP)
    if clasificacion == "necesita_aclaracion":
        logger.warning(f"‚ö†Ô∏è  Intenci√≥n NO clara - Pidiendo aclaraciones")
        
        # Usar la pregunta generada por el LLM o fallback
        pregunta = pregunta_aclaracion or "¬øEn qu√© puedo ayudarte hoy?"
        
        logger.info(f"‚ùì Pregunta: {pregunta}")
        
        # Agregar mensaje de aclaraci√≥n y NO avanzar (loop interno)
        return Command(
            update={
                "clasificacion_mensaje": "necesita_aclaracion",
                "confianza_clasificacion": confianza,
                "modelo_clasificacion_usado": modelo_usado,
                "messages": messages + [AIMessage(content=pregunta)]
            },
            goto="END"  # END = Loop, espera nuevo mensaje del usuario
        )
    
    # Validar seg√∫n tipo de usuario
    clasificacion_validada = validar_clasificacion_por_tipo_usuario(
        clasificacion,
        tipo_usuario
    )
    
    if clasificacion != clasificacion_validada:
        logger.warning(
            f"‚ö†Ô∏è  Clasificaci√≥n ajustada: {clasificacion} ‚Üí {clasificacion_validada}"
        )
        clasificacion = clasificacion_validada
    
    # Calcular tiempo
    tiempo_ms = int((time.time() - inicio) * 1000)
    logger.info(f"‚è±Ô∏è  Tiempo: {tiempo_ms}ms")
    
    # Registrar en BD
    session_id_val = state.get("session_id")
    session_id = str(session_id_val) if session_id_val else ""
    
    if not session_id:
        thread_id_val = state.get("thread_id")
        session_id = str(thread_id_val) if thread_id_val else f"sess_{user_id}"
        
    registrar_clasificacion_bd(
        user_id=user_id,
        session_id=session_id,
        mensaje=ultimo_mensaje,
        clasificacion=clasificacion,
        modelo_usado=modelo_usado,
        tiempo_ms=tiempo_ms,
        herramientas_seleccionadas=[]
    )
    
    # ‚úÖ Determinar siguiente nodo seg√∫n clasificaci√≥n
    destinos = {
        "medica": "recuperacion_medica",
        "personal": "recuperacion_episodica",
        "solicitud_cita_paciente": "recepcionista",
        "chat": "generacion_resumen"
    }
    
    goto = destinos.get(clasificacion, "generacion_resumen")
    
    logger.info(f"‚úÖ Filtrado completado ‚Üí Siguiente: {goto}\n")
    
    return Command(
        update={
            "clasificacion_mensaje": clasificacion,
            "confianza_clasificacion": confianza,
            "modelo_clasificacion_usado": modelo_usado,
            "tiempo_clasificacion_ms": tiempo_ms
        },
        goto=goto
    )

# Wrapper para compatibilidad con grafo
def nodo_filtrado_inteligente_wrapper(state: WhatsAppAgentState) -> Command[Any]:
    """Wrapper para LangGraph - retorna Command directamente."""
    return nodo_filtrado_inteligente(state)
